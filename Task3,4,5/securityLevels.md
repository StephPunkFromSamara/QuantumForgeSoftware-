Уровни защиты в текущем боте RAG

На основе анализа кода test.py и логов выполнения.


## 1. No Filter (Без фильтрации)

Описание
	•	no_filter=True
	•	Контекст и запрос отправляются напрямую в LLM без каких-либо ограничений.

## 2. Pre-Prompt (Фильтрация запроса)

Описание
	•	Включается через pre_prompt=True или full_protection=True.
	•	Фильтрует опасные ключевые слова на уровне запроса до генерации LLM.

Как работает
	•	Функция apply_pre_prompt_filter(query) проверяет запрос на ключевые слова: “взлом”, “эксплойт”, “обойти защиту”.
	•	Если обнаружено запрещённое слово, возвращает отказ:

Извините, я не могу помочь с этим запросом.

## 3. Post-Check (Фильтрация ответа)

Описание
	•	Включается через post_check=True или full_protection=True.
	•	После генерации ответа проверяется на запрещённые фразы.

Как работает
	•	Функция apply_post_check_filter(answer) проверяет ответ на слова/фразы: “взломать”, “эксплойт”, “несанкционированный доступ”.
	•	Если обнаружено, ответ заменяется на:
Плюсы
	•	Защищает пользователя от потенциально опасного текста.

Минусы
	•	Модель уже могла сгенерировать опасный текст до фильтрации.
	•	Не защищает полностью, если ответы стримятся или попадают в логи.

## 4. Full Protection (Pre-Prompt + Post-Check)

Описание
	•	Включается через full_protection=True.
	•	Комбинирует фильтрацию запроса и проверку ответа.

Особенности реализации
	•	Опасные запросы блокируются на уровне Pre-Prompt.
	•	Ответы проверяются и при необходимости заменяются Post-Check.




## Вывод

Текущий бот использует Pre-Prompt и Post-Check, которые включаются как Full Protection. Для production стоит добавить quarantine и redaction на этапе индексации, а также semantic reranker для дополнительной безопасности.

## Что не реализовано в боте
 
	•	Quarantine / redaction при индексации документов (ingest-time).
	•	Semantic reranker между retrieval и prompt assembly.
	•	Redaction секретов в чанках перед формированием промпта.
	•	Логирование только безопасных ответов.
